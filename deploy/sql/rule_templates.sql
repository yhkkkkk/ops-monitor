use watchalert;
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('Exporter异常', 'Prometheus', '{\"promQL\":\"up == 0\"}', 0, 30, 60, '节点: ${instance} , Exporter 异常, 请及时处理!', 'Node');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('节点分区使用率大于80%', 'Prometheus', '{\"promQL\":\"(node_filesystem_size_bytes{fstype=~\\\"ext.?|xfs\\\",mountpoint=~\\\"/|/rootfs\\\"}-node_filesystem_free_bytes{fstype=~\\\"ext.?|xfs\\\",mountpoint=~\\\"/|/rootfs\\\"}) *100/(node_filesystem_avail_bytes {fstype=~\\\"ext.?|xfs\\\",mountpoint=~\\\"/|/rootfs\\\"}+(node_filesystem_size_bytes{fstype=~\\\"ext.?|xfs\\\",mountpoint=~\\\"/|/rootfs\\\"}-node_filesystem_free_bytes{fstype=~\\\"ext.?|xfs\\\",mountpoint=~\\\"/|/rootfs\\\"})) \\u003e 80\"}', 0, 30, 180, '节点分区使用率大于 80%', 'Node');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('节点CPU使用率大于80%', 'Prometheus', '{\"promQL\":\"100 - (avg(irate(node_cpu_seconds_total{mode=\\\"idle\\\"}[5m])) by (instance,tags) * 100) \\u003e 80\"}', 0, 30, 180, '节点 CPU 使用率大于 80% ,持续时间 2m', 'Node');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('节点内存使用率超过80%', 'Prometheus', '{\"promQL\":\"(node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 \\u003c 20) * on(instance,tags) group_left (nodename) node_uname_info{nodename=~\\\".+\\\"}\"}', 0, 10, 180, '节点内存使用率超过 80%, 持续时间 2m', 'Node');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('APISixEtcdUnreachable', 'Prometheus', '{\"promQL\":\"absent(apisix_etcd_reachable{job=\\\"Prod-ali-kubernetes-Apisix\\\"}) == 1\"}', 0, 10, 60, '生产环境APISix etcd服务器无法访问。配置更改可能无法生效。', 'ApiSix');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('APISixHighRequestRate', 'Prometheus', '{\"promQL\":\"rate(apisix_http_requests_total{job=\\\"Prod-ali-kubernetes-Apisix\\\"}[5m]) \\u003e 1000\"}', 0, 30, 300, '生产环境APISix服务正在经历高请求速率。每秒超过1000个请求。', 'ApiSix');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('APISixNginxMetricErrors', 'Prometheus', '{\"promQL\":\"apisix_nginx_metric_errors_total{job=\\\"Prod-ali-kubernetes-Apisix\\\"} \\u003e 0\"}', 0, 10, 60, '生产环境在APISix中收集nginx指标时发生了错误。', 'ApiSix');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('APISixNodeInfoMissing', 'Prometheus', '{\"promQL\":\"apisix_nginx_metric_errors_total{job=\\\"Prod-ali-kubernetes-Apisix\\\"} \\u003e 0\"}', 0, 10, 60, '生产环境APISix节点信息丢失。这可能表示节点或监控设置存在问题。', 'ApiSix');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('APISixNode小于3', 'Prometheus', '{\"promQL\":\"sum(apisix_node_info{job=\\\"Prod-ali-kubernetes-Apisix\\\"}) \\u003c 3\"}', 0, 10, 60, '生产环境APISix节点小于3台性能有下降。', 'ApiSix');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('APISix活跃连接接近峰值', 'Prometheus', '{\"promQL\":\"sum(apisix_nginx_http_current_connections{state=\\\"active\\\",job=\\\"Prod-ali-kubernetes-Apisix\\\"})by (job) \\u003e= 1258272\"}', 0, 10, 60, 'APISix活跃连接接近峰值尽快扩容,当前活跃数量「${value}」', 'ApiSix');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('ApisixEtcdClusterStatus', 'Prometheus', '{\"promQL\":\"sum(etcd_server_has_leader{job=\\\"Prod-ali-kubernetes-apisix-etcd\\\"}) != 3\"}', 0, 10, 180, '检测到生产Apisix-Etcd集群节点数量不满足预期(应为3个节点),可能存在节点退出或Leader丢失情况,当前剩余节点「${value}」', 'ApiSix');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('ApisixEtcdleader', 'Prometheus', '{\"promQL\":\"sum(etcd_server_is_leader{job=\\\"Prod-ali-kubernetes-apisix-etcd\\\"}) != 1\"}', 0, 10, 180, '生产Apisix-Etcd集群存在脑裂(应为1个主节点).', 'ApiSix');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('ApisixEtcdUp', 'Prometheus', '{\"promQL\":\"absent(etcd_server_has_leader{job=\\\"Prod-ali-kubernetes-apisix-etcd\\\"}) == 1\"}', 0, 10, 60, 'Etcd节点宕机', 'ApiSix');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('Apisix Etcd leader变更频繁', 'Prometheus', '{\"promQL\":\"changes(etcd_server_leader_changes_seen_total{job=\\\"Prod-ali-kubernetes-apisix-etcd\\\"}[1h]) \\u003e 5\"}', 0, 30, 180, '最近1小时内Etcd集群主节点切换次数较多,可能由网络问题、OOM或升级等原因导致,具体次数为「${value}」', 'ApiSix');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('ApisixEtcdDbSize接近容量限制', 'Prometheus', '{\"promQL\":\"etcd_mvcc_db_total_size_in_bytes / (1024 * 1024) \\u003e etcd_server_quota_backend_bytes / (1024 * 1024) * 0.8\"}', 0, 10, 180, 'Etcd后端数据库${instance}接近容量限制80%,当前值当前使用率百分比「${value}%」', 'ApiSix');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('ApisixEtcdBackend提交延迟异常', 'Prometheus', '{\"promQL\":\"histogram_quantile(0.99, sum(rate(etcd_disk_backend_commit_duration_seconds_bucket{job=\\\"Prod-ali-kubernetes-apisix-etcd\\\"}[5m])) by (instance, le)) \\u003e 0.25\"}', 0, 30, 180, 'Etcd后端提交操作的延迟较长${instance},可能导致磁盘读写异常当前值为「${value}」.', 'ApiSix');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('ApisixEtcdRaft议问题', 'Prometheus', '{\"promQL\":\"rate(etcd_server_proposals_failed_total{job=\\\"Prod-ali-kubernetes-apisix-etcd\\\"}[1m]) \\u003e 0 or etcd_server_proposals_pending{job=\\\"Prod-ali-kubernetes-apisix-etcd\\\"} \\u003e 0 or etcd_server_proposals_committed_total{job=\\\"Prod-ali-kubernetes-apisix-etcd\\\"} - etcd_server_proposals_applied_total{job=\\\"Prod-ali-kubernetes-apisix-etcdtcd\\\"} \\u003e 0\"}', 0, 15, 180, '检测到Etcd集群中Raft协议存在问题, ${instance}可能出现提交失败、积压或提交与应用的差值大于0的情况,当前值为「${value}」.', 'ApiSix');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('Elasticsearch 堆使用率过高', 'Prometheus', '{\"promQL\":\"(elasticsearch_jvm_memory_used_bytes{area=\\\"heap\\\"} / elasticsearch_jvm_memory_max_bytes{area=\\\"heap\\\"}) * 100 \\u003e 80\"}', 0, 10, 180, 'The heap usage is over 80% 当前使用率: ${value}', 'Elasticsearch');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('Elasticsearch 磁盘空间不足', 'Prometheus', '{\"promQL\":\"elasticsearch_filesystem_data_available_bytes / elasticsearch_filesystem_data_size_bytes * 100 \\u003c 20\"}', 10, 0, 180, 'The disk usage is over 80% 当前使用率: ${value}', 'Elasticsearch');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('Elasticsearch 集群红色', 'Prometheus', '{\"promQL\":\"elasticsearch_cluster_health_status{color=\\\"red\\\"} == 1\"}', 0, 10, 180, 'Elastic Cluster Red status 当前值: ${value}', 'Elasticsearch');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('Elasticsearch 集群黄色', 'Prometheus', '{\"promQL\":\"elasticsearch_cluster_health_status{color=\\\"yellow\\\"} == 1\"}', 0, 30, 180, 'Elastic Cluster Yellow status 当前值: ${value}', 'Elasticsearch');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('Elasticsearch 节点状态', 'Prometheus', '{\"promQL\":\"elasticsearch_node_stats_up \\u003c 1\"}', 0, 10, 180, 'Elasticsearch 节点故障: ${value} 请及时处理！', 'Elasticsearch');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('Elasticsearch 重新定位分片的时间过长', 'Prometheus', '{\"promQL\":\"elasticsearch_cluster_health_relocating_shards \\u003e 0\"}', 0, 60, 600, 'Elasticsearch已经重新定位碎片10分钟了, 当前值: ${value}', 'Elasticsearch');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('Elasticsearch 初始化分片时间过长', 'Prometheus', '{\"promQL\":\"elasticsearch_cluster_health_initializing_shards \\u003e 0\"}', 0, 60, 600, 'Elasticsearch已经初始化碎片10分钟了, 当前值:${value}', 'Elasticsearch');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('Elasticsearch 集群中缺少节点', 'Prometheus', '{\"promQL\":\"elasticsearch_cluster_health_number_of_nodes \\u003c 3\"}', 0, 10, 180, 'Elasticsearch集群中节点丢失 当前集群节点数: ${value}', 'Elasticsearch');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('Elasticsearch 慢查询告警', 'Prometheus', '{\"promQL\":\"irate(elasticsearch_indices_search_query_time_seconds[5m]) \\u003e 0.2\"}', 0, 10, 60, 'Elasticsearch集群出现慢查询超过200ms', 'Elasticsearch');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('Kafka Node Inconsistent Numbers', 'Prometheus', '{\"promQL\":\"kafka_brokers{job=\\\"test-kafka-cluster\\\"} \\u003c 3\"}', 0, 10, 60, 'kafka集群: ${instance} Kafka集群节点数不符合预期三节点', 'Kafka');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('Kafka 集群 Topic xxx副本同步小于 3', 'Prometheus', '{\"promQL\":\"sum(kafka_topic_partition_in_sync_replica{job=\\\"Flink-Kafka-Cluster\\\",topic=\\\"xxx\\\"}) by(topic,job) \\u003c 3\"}', 0, 10, 60, 'kafka集群: ${instance} Kafka 集群 Topic ${topic} 副本小于 3', 'Kafka');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('集群 Pod 副本崩溃导致重启', 'Prometheus', '{\"promQL\":\"sum(changes(kube_pod_container_status_restarts_total{namespace=\\\"zprod\\\"}[10m]) \\u003e= 1) by (pod,instance,env)\"}', 0, 10, 60, '集群环境: ${env} Pod: ${pod} 重启事件次数: ${value}', 'Kubernetes');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('Kubernetes 节点尚未准备好', 'Prometheus', '{\"promQL\":\"kube_node_status_condition{condition=\\\"Ready\\\",status=\\\"true\\\"} == 0\"}', 0, 30, 300, 'Kubernetes Node not ready, instance: ${instance}', 'Kubernetes');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('Kubernetes 客户端证书下周到期', 'Prometheus', '{\"promQL\":\"apiserver_client_certificate_expiration_seconds_count{job=\\\"apiserver\\\"} \\u003e 0 and histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job=\\\"apiserver\\\"}[5m]))) \\u003c 7*24*60*60\"}', 0, 30, 300, 'Kubernetes client certificate expires next week, instance: ${instance}', 'Kubernetes');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('Kubernetes 卷磁盘空间不足', 'Prometheus', '{\"promQL\":\"kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes * 100 \\u003c 10\"}', 0, 30, 300, 'Kubernetes Volume out of disk space, instance: ${instance}', 'Kubernetes');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('Kubernetes HPA 指标不可用', 'Prometheus', '{\"promQL\":\"kube_horizontalpodautoscaler_status_condition{status=\\\"false\\\", condition=\\\"ScalingActive\\\"} == 1\"}', 0, 30, 300, 'Kubernetes HPA metrics unavailability, instance: ${instance}', 'Kubernetes');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('Kubernetes API 服务器错误率很高', 'Prometheus', '{\"promQL\":\"sum(rate(apiserver_request_total{job=\\\"apiserver\\\",code=~\\\"^(?:5..)$\\\"}[1m])) / sum(rate(apiserver_request_total{job=\\\"apiserver\\\"}[1m])) * 100 \\u003e 3\"}', 0, 30, 300, 'Kubernetes API server errors, instance: ${instance}', 'Kubernetes');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('Kubernetes 客户端证书即将过期', 'Prometheus', '{\"promQL\":\"apiserver_client_certificate_expiration_seconds_count{job=\\\"apiserver\\\"} \\u003e 0 and histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job=\\\"apiserver\\\"}[5m]))) \\u003c 24*60*60\"}', 0, 30, 300, 'Kubernetes client certificate expires soon, instance: ${instance}', 'Kubernetes');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('容器CPU利用率超过80%', 'Prometheus', '{\"promQL\":\"(sum(rate(container_cpu_usage_seconds_total{container!=\\\"\\\"}[5m])) by (pod, container) / sum(container_spec_cpu_quota{container!=\\\"\\\"}/container_spec_cpu_period{container!=\\\"\\\"}) by (pod, container) * 100) \\u003e 80\"}', 0, 10, 180, 'Container High CPU utilization is above 80%, ${instance}', 'Docker');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('容器内存使用率超过80%', 'Prometheus', '{\"promQL\":\"(sum(container_memory_working_set_bytes{name!=\\\"\\\"}) BY (instance, name) / sum(container_spec_memory_limit_bytes \\u003e 0) BY (instance, name) * 100) \\u003e 80\"}', 0, 10, 180, 'Container High Memory usage is above 80%, ${instance}', 'Docker');
INSERT  ignore INTO `rule_templates` (`rule_name`, `datasource_type`, `prometheus_config`, `severity`, `eval_interval`, `for_duration`, `annotations`, `rule_group_name`) VALUES ('容器卷使用率超过80%', 'Prometheus', '{\"promQL\":\"(1 - (sum(container_fs_inodes_free{name!=\\\"\\\"}) BY (instance) / sum(container_fs_inodes_total) BY (instance))) * 100 \\u003e 80\"}', 0, 30, 300, 'Container Volume usage is above 80%, ${instance}', 'Docker');
